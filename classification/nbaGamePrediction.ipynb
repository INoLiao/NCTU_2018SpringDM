{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - NBA Game Winning Prediction by Classification\n",
    "- The report is a simplified version of Data Mining Final Project.\n",
    "- The raw data are team_season_all.csv, team_playoff_all.csv\n",
    "- nba_preprocessed.csv is the intermediate data for feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. Motivation\n",
    "2. Problem Definition\n",
    "3. Data Preprocessing\n",
    "4. Feature Extraction (Selection & Engineering)\n",
    "5. Model Training\n",
    "6. NBA Game Winning Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cross Validation & Grid Search\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Motivation:\n",
    "- Predict winners of NBA 2018 playoff games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problem Definition:\n",
    "- Input: Averaged team performance of previous 5 games.\n",
    "- Output: Win or lose the match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing:\n",
    "- Remove NaN, pair teams of games, and check the validity.\n",
    "- Input: team_season_all.csv and team_playoff_all.csv\n",
    "- Output: nba_preprocessed.csv\n",
    "- Note: 這部分我寫成nbaDataPreprocessing.py(有一併上傳)，已經事先跑過並產生nba_preprocessed.csv這個檔案了，所以助教可以不需要再跑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction\n",
    "- Feature Selection & Feature Engineering\n",
    "- Input: nba_preprocessed.csv\n",
    "- Output: X(Attributes) and Y(Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function - featureEng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param X: pandas.DataFrame\n",
    "# @param featureSel: int\n",
    "# @return X: pandas.DataFrame\n",
    "def featureEng(X, featureSel=None):\n",
    "    # Feature Engineering\n",
    "    if not featureSel or featureSel == 0:\n",
    "        return X\n",
    "    if featureSel == 1:\n",
    "        X['PTS_DIFF'] = X['PTS_A'] - X['PTS_B']\n",
    "    elif featureSel == 2:\n",
    "        attriToDrop = ['PTS_A', 'PTS_B']\n",
    "        X = X.drop(columns=attriToDrop)\n",
    "    elif featureSel == 3:\n",
    "        X['PTS_DIFF'] = X['PTS_A'] - X['PTS_B']\n",
    "        attriToDrop = ['PTS_A', 'PTS_B']\n",
    "        X = X.drop(columns=attriToDrop)\n",
    "    elif featureSel == 4:\n",
    "        attriToDrop = [\n",
    "            'FGM_A', 'FGA_A', '3PM_A', '3PA_A', 'FTM_A', 'FTA_A', 'OREB_A', 'DREB_A', 'PF_A', \n",
    "            'FGM_B', 'FGA_B', '3PM_B', '3PA_B', 'FTM_B', 'FTA_B', 'OREB_B', 'DREB_B', 'PF_B'\n",
    "        ]\n",
    "        X['PTS_DIFF'] = X['PTS_A'] - X['PTS_B']\n",
    "        X['STL+BLK_A'] = X['STL_A'] + X['BLK_A']\n",
    "        X['STL+BLK_B'] = X['STL_B'] + X['BLK_B']\n",
    "        attriToDrop += ['PTS_A', 'PTS_B', 'STL_A', 'STL_B', 'BLK_A', 'BLK_B']\n",
    "        X = X.drop(columns=attriToDrop)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function - featureExtraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param dfFile: pandas.DataFrame ('nba_preprocessed.csv')\n",
    "# @param dateStart, dateEnd: str in the format of 'YYYY-MM-DD'\n",
    "# @param period: int\n",
    "# @param featureSel: int\n",
    "# @return X, Y: pandas.DataFrame\n",
    "# featureExtraction() outputs X, Y for model training.\n",
    "def featureExtraction(dfFile, dateStart='1000-01-01', dateEnd='2999-12-31', period=5, featureSel=None):\n",
    "    df = pd.read_csv(dfFile)\n",
    "    \n",
    "    # Date selection\n",
    "    df = df.loc[(df.Date_A >= dateStart) & (df.Date_A <= dateEnd), :].reset_index(drop=True)\n",
    "    \n",
    "    # Get label Y\n",
    "    Y = df[['W/L_A']]\n",
    "    Y = Y.rename(columns={'W/L_A': 'Label'})\n",
    "    \n",
    "    # Get averaged attributes X\n",
    "    for idx, row in df.iterrows():\n",
    "        df_sel = df.loc[df.Date_A <= row['Date_A'], :].reset_index(drop=True)\n",
    "        \n",
    "        # Process of Team_A\n",
    "        gamePlayed_A = df_sel.loc[df_sel.Team_A == row['Team_A'], :]\n",
    "        if len(gamePlayed_A) == 1:\n",
    "            X_A = gamePlayed_A.loc[(gamePlayed_A.Team_A == row['Team_A']), :].sort_values(by=['Date_A'], ascending=False).iloc[0:1, 0:24].reset_index(drop=True)\n",
    "        elif len(gamePlayed_A) < period:\n",
    "            X_A = gamePlayed_A.loc[(gamePlayed_A.Team_A == row['Team_A']), :].sort_values(by=['Date_A'], ascending=False).iloc[1:len(gamePlayed_A), 0:24].reset_index(drop=True)\n",
    "        else:\n",
    "            X_A = gamePlayed_A.loc[(gamePlayed_A.Team_A == row['Team_A']), :].sort_values(by=['Date_A'], ascending=False).iloc[1:period+1, 0:24].reset_index(drop=True)\n",
    "        \n",
    "        # Process of Team_B\n",
    "        gamePlayed_B = df_sel.loc[df_sel.Team_A == row['Team_B'], :]\n",
    "        if len(gamePlayed_B) == 1:\n",
    "            X_B = gamePlayed_B.loc[(gamePlayed_B.Team_A == row['Team_B']), :].sort_values(by=['Date_A'], ascending=False).iloc[0:1, 0:24].reset_index(drop=True)\n",
    "        elif len(gamePlayed_B) < period:\n",
    "            X_B = gamePlayed_B.loc[(gamePlayed_B.Team_A == row['Team_B']), :].sort_values(by=['Date_A'], ascending=False).iloc[1:len(gamePlayed_B), 0:24].reset_index(drop=True)\n",
    "        else:\n",
    "            X_B = gamePlayed_B.loc[(gamePlayed_B.Team_A == row['Team_B']), :].sort_values(by=['Date_A'], ascending=False).iloc[1:period+1, 0:24].reset_index(drop=True)\n",
    "        \n",
    "        # Drop unnecessary attributes\n",
    "        colToDrop = ['Home/Away_A'] + ['Team_A', 'Date_A', 'W/L_A', 'Score_A', 'Opponent_A']\n",
    "        X_A = X_A.drop(columns=colToDrop)\n",
    "        X_B = X_B.drop(columns=colToDrop)\n",
    "        \n",
    "        # Rename X_B's columns\n",
    "        X_B = X_B.rename(columns=lambda x: x[0:-2] + '_B')\n",
    "        \n",
    "        # Get X_single = [Home/Away_A + X_A + X_B]\n",
    "        X_single = pd.DataFrame(data=pd.concat([X_A.mean(), X_B.mean()])).transpose()\n",
    "        X_single = pd.concat([pd.DataFrame(data={'Home/Away_A': [row['Home/Away_A']]}), X_single], axis=1)\n",
    "        \n",
    "        # Concatenation dataFrames by row\n",
    "        if idx == 0:\n",
    "            X = X_single\n",
    "        else:\n",
    "            X = pd.concat([X, X_single], ignore_index=True)\n",
    "        \n",
    "    # Feature Engineering\n",
    "    X = featureEng(X, featureSel)\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2015-08-01'\n",
    "dateEnd = '2018-04-13'\n",
    "period = 5\n",
    "featureSel = 3\n",
    "X, Y = featureExtraction(dfFile, dateStart, dateEnd, period, featureSel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attributes X\n",
    "- First two rows are the same, since there are no previous games available to be averaged at the beginning of a season.\n",
    "- _A means Team_A's attributes and _B means Team_B's attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home/Away_A</th>\n",
       "      <th>FG%_A</th>\n",
       "      <th>FGM_A</th>\n",
       "      <th>FGA_A</th>\n",
       "      <th>3P%_A</th>\n",
       "      <th>3PM_A</th>\n",
       "      <th>3PA_A</th>\n",
       "      <th>FT%_A</th>\n",
       "      <th>FTM_A</th>\n",
       "      <th>FTA_A</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA_B</th>\n",
       "      <th>REB_B</th>\n",
       "      <th>OREB_B</th>\n",
       "      <th>DREB_B</th>\n",
       "      <th>AST_B</th>\n",
       "      <th>STL_B</th>\n",
       "      <th>BLK_B</th>\n",
       "      <th>TOV_B</th>\n",
       "      <th>PF_B</th>\n",
       "      <th>PTS_DIFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.42500</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0.69600</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>23.00</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.42500</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0.69600</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>23.00</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.48150</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>23.50</td>\n",
       "      <td>0.77300</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>21.50</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>35.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.45600</td>\n",
       "      <td>37.666667</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.395333</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.75900</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>23.00</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>-9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.43675</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>24.25</td>\n",
       "      <td>0.78525</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>22.75</td>\n",
       "      <td>...</td>\n",
       "      <td>22.8</td>\n",
       "      <td>50.6</td>\n",
       "      <td>14.2</td>\n",
       "      <td>36.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>20.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>-14.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Home/Away_A    FG%_A      FGM_A  FGA_A     3P%_A      3PM_A  3PA_A  \\\n",
       "0            1  0.42500  37.000000   87.0  0.368000   7.000000  19.00   \n",
       "1            0  0.42500  37.000000   87.0  0.368000   7.000000  19.00   \n",
       "2            0  0.48150  39.500000   82.5  0.434000  10.500000  23.50   \n",
       "3            1  0.45600  37.666667   83.0  0.395333   9.333333  23.00   \n",
       "4            1  0.43675  36.500000   84.0  0.359000   8.750000  24.25   \n",
       "\n",
       "     FT%_A      FTM_A  FTA_A    ...     FTA_B  REB_B  OREB_B  DREB_B  AST_B  \\\n",
       "0  0.69600  16.000000  23.00    ...      17.0   50.0    11.0    39.0   26.0   \n",
       "1  0.69600  16.000000  23.00    ...      28.0   45.0    16.0    29.0   19.0   \n",
       "2  0.77300  16.500000  21.50    ...      30.0   51.0    15.5    35.5   19.5   \n",
       "3  0.75900  17.333333  23.00    ...      25.0   52.5    15.5    37.0   22.5   \n",
       "4  0.78525  17.750000  22.75    ...      22.8   50.6    14.2    36.4   23.0   \n",
       "\n",
       "   STL_B  BLK_B  TOV_B  PF_B  PTS_DIFF  \n",
       "0    5.0    7.0   10.0  21.0       2.0  \n",
       "1   11.0    5.0   13.0  18.0      -3.0  \n",
       "2    3.5    3.5   12.5  17.5       7.0  \n",
       "3    9.5    8.0   15.0  26.5      -9.5  \n",
       "4    7.8    8.4   20.2  24.6     -14.7  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Y\n",
    "- Y = 1 means Team_A wins and Team_B loses\n",
    "- Y = 0 means Team_A loses and Team_B wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label\n",
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "- Find optimized model parameters by \"Cross Validation and Grid Search (CVGS)\"\n",
    "    - 若是parameter sweep的維度太高，會跑太久，所以這份作業中我將維度降低，實際上在Final Project中，維度設定較大，需要跑一個禮拜左右。\n",
    "- Classifier candidates:\n",
    "    - Logistic Regression Classification\n",
    "    - XGBoost Classification\n",
    "    - Random Forest Classification\n",
    "    - AdaBoost Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function - CrossValidationGridSearchNested()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidationGridSearchNested(X_data, Y_data, num_trials, fold_num, est_classifcation, tuned_param, scoring):\n",
    "    max_score = -1\n",
    "    best_estimator = est_classifcation\n",
    "    is_tuned_param_empty = (tuned_param == []) | (tuned_param == None)\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        inner_cv = StratifiedKFold(n_splits=fold_num, random_state=i, shuffle=True)\n",
    "        outer_cv = StratifiedKFold(n_splits=fold_num, random_state=i+1, shuffle=True)\n",
    "        \n",
    "        if(is_tuned_param_empty):\n",
    "            param_score = cross_val_score(est_classifcation, X=X_data, y=Y_data, cv=outer_cv, scoring=scoring).mean()\n",
    "        else:\n",
    "            # Non_nested parameter search and scoring\n",
    "            clf = GridSearchCV(estimator=est_classifcation, param_grid=tuned_param, cv=inner_cv, scoring=scoring)\n",
    "            clf.fit(X_data, Y_data)\n",
    "        \n",
    "            # CV with parameter optimization\n",
    "            param_score = cross_val_score(clf.best_estimator_, X=X_data, y=Y_data, cv=outer_cv, scoring=scoring).mean()\n",
    "            \n",
    "        if(param_score > max_score):\n",
    "            max_score = param_score\n",
    "            if(is_tuned_param_empty):\n",
    "                best_estimator = est_classifcation\n",
    "            else:\n",
    "                best_estimator = clf.best_estimator_\n",
    "            \n",
    "        progress = (i+1)/num_trials*100\n",
    "        print(f'> progress = {progress}%')\n",
    "    \n",
    "    return (max_score, best_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> progress = 33.33333333333333%\n",
      "> progress = 66.66666666666666%\n",
      "> progress = 100.0%\n",
      "Execution time = 188.47410702705383\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "# Model Settings\n",
    "model = LogisticRegression()\n",
    "tuned_parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'max_iter': [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 3\n",
    "(max_score, logiRegrCVGS) = CrossValidationGridSearchNested(X, Y, NUM_TRIALS, 10, model, tuned_parameters, 'roc_auc')\n",
    "\n",
    "print('Execution time =', time.time() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> progress = 33.33333333333333%\n",
      "> progress = 66.66666666666666%\n",
      "> progress = 100.0%\n",
      "Execution time = 428.78781604766846\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "# Model Settings\n",
    "model = XGBClassifier()\n",
    "tuned_parameters = {\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'n_estimators': [100, 200],\n",
    "    'gamma': [x/10 for x in range(0, 2)]\n",
    "}\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 3\n",
    "(max_score, xgbcCVGS) = CrossValidationGridSearchNested(X, Y, NUM_TRIALS, 10, model, tuned_parameters, 'roc_auc')\n",
    "\n",
    "print('Execution time =', time.time() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> progress = 33.33333333333333%\n",
      "> progress = 66.66666666666666%\n",
      "> progress = 100.0%\n",
      "Execution time = 2367.319732904434\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "# Model Settings\n",
    "model = RandomForestClassifier()\n",
    "tuned_parameters = {\n",
    "    'n_estimators': [800, 1000],\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [None, 10]\n",
    "}\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 3\n",
    "(max_score, randomForestCVGS) = CrossValidationGridSearchNested(X, Y, NUM_TRIALS, 10, model, tuned_parameters, 'roc_auc')\n",
    "\n",
    "print('Execution time =', time.time() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> progress = 33.33333333333333%\n",
      "> progress = 66.66666666666666%\n",
      "> progress = 100.0%\n",
      "Execution time = 1300.339076757431\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "# Model Settings\n",
    "model = AdaBoostClassifier()\n",
    "tuned_parameters = {\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'n_estimators': [50, 600, 1000],\n",
    "}\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 3\n",
    "(max_score, adaBoostCVGS) = CrossValidationGridSearchNested(X, Y, NUM_TRIALS, 10, model, tuned_parameters, 'roc_auc')\n",
    "\n",
    "print('Execution time =', time.time() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Logistic Regression ...\n",
      ">> XGBoost ...\n",
      ">> Random Forest ...\n",
      ">> AdaBoost ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.1, n_estimators=1000, random_state=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('>> Logistic Regression ...')\n",
    "logiRegr = LogisticRegression()\n",
    "logiRegr.fit(X, Y)\n",
    "logiRegrCVGS.fit(X, Y)\n",
    "\n",
    "print('>> XGBoost ...')\n",
    "xgbc = XGBClassifier()\n",
    "xgbc.fit(X, Y)\n",
    "xgbcCVGS.fit(X, Y)\n",
    "\n",
    "print('>> Random Forest ...')\n",
    "randomForest = RandomForestClassifier()\n",
    "randomForest.fit(X, Y)\n",
    "randomForestCVGS.fit(X, Y)\n",
    "\n",
    "print('>> AdaBoost ...')\n",
    "adaBoost = AdaBoostClassifier()\n",
    "adaBoost.fit(X, Y)\n",
    "adaBoostCVGS.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsLUT = {\n",
    "    'logiRegr': logiRegr,\n",
    "    'logiRegrCVGS': logiRegrCVGS,\n",
    "    'xgbc': xgbc,\n",
    "    'xgbcCVGS': xgbcCVGS,\n",
    "    'randomForest': randomForest,\n",
    "    'randomForestCVGS': randomForestCVGS,\n",
    "    'adaBoost': adaBoost,\n",
    "    'adaBoostCVGS': adaBoostCVGS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. NBA 2018 Playoff Games Winning Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function - attriGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param dfFile: pandas.DataFrame (from 'nba_preprocessed.csv')\n",
    "# @param date: str in the format of 'YYYY-MM-DD'\n",
    "# @param period: int (Number of previous games to be considered)\n",
    "# @param Team_A, Team_B: str\n",
    "# @param homeAway: int (None for played game prediction)\n",
    "# @param featureSel: int\n",
    "# @return X: pandas.DataFrame\n",
    "def attriGen(df, date, period, Team_A, Team_B, homeAway=None, featureSel=None):\n",
    "    # True Home/Away at the game day\n",
    "    if homeAway is None:\n",
    "        df_gameDay = df.loc[(df.Date_A == date) & (df.Team_A == Team_A) & (df.Team_B == Team_B), :].reset_index(drop=True)\n",
    "        homeAway = int(df_gameDay['Home/Away_A'])\n",
    "    \n",
    "    # Date selections\n",
    "    df = df.loc[df.Date_A < date, :].reset_index(drop=True)\n",
    "    X_A = df.loc[(df.Team_A == Team_A), :].sort_values(by=['Date_A'], ascending=False).iloc[0:period, 0:24].reset_index(drop=True)\n",
    "    X_B = df.loc[(df.Team_A == Team_B), :].sort_values(by=['Date_A'], ascending=False).iloc[0:period, 0:24].reset_index(drop=True)\n",
    "    \n",
    "    # Drop unnecessary attributes\n",
    "    colToDrop = ['Home/Away_A'] + ['Team_A', 'Date_A', 'W/L_A', 'Score_A', 'Opponent_A']\n",
    "    X_A = X_A.drop(columns=colToDrop)\n",
    "    X_B = X_B.drop(columns=colToDrop)\n",
    "    \n",
    "    # Rename X_away's columns\n",
    "    X_B = X_B.rename(columns=lambda x: x[0:-2] + '_B')\n",
    "    \n",
    "    # Get X = [Home/Away_A + X_A + X_B]\n",
    "    X = pd.DataFrame(data=pd.concat([X_A.mean(), X_B.mean()])).transpose()\n",
    "    X = pd.concat([pd.DataFrame(data={'Home/Away_A': [homeAway]}), X], axis=1)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    X = featureEng(X, featureSel)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function - groundTruthGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param dfFile: pandas.DataFrame (from 'nba_preprocessed.csv')\n",
    "# @param date: str in the format of 'YYYY-MM-DD'\n",
    "# @param Team_A, Team_B: str\n",
    "# @param featureSel: int\n",
    "# @return X_groundTruth, Y_groundTruth: pandas.DataFrame\n",
    "def groundTruthGen(df, date, Team_A, Team_B, featureSel=None):\n",
    "    # Date selections\n",
    "    df = df.loc[(df.Date_A == date) & (df.Team_A == Team_A) & (df.Team_B == Team_B), :].reset_index(drop=True)\n",
    "\n",
    "    # Get label Y\n",
    "    Y_groundTruth = df[['W/L_A']]\n",
    "    Y_groundTruth = Y_groundTruth.rename(columns={'W/L_A': 'Label'})\n",
    "    \n",
    "    # Drop unnecessary attributes\n",
    "    colToDrop = [\n",
    "        'Team_A', 'Date_A', 'W/L_A', 'Score_A', 'Opponent_A', \n",
    "        'Team_B', 'Date_B', 'W/L_B', 'Home/Away_B', 'Score_B', 'Opponent_B'\n",
    "    ]\n",
    "    X_groundTruth = df.drop(columns=colToDrop)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    X_groundTruth = featureEng(X_groundTruth, featureSel)\n",
    "    \n",
    "    return X_groundTruth, Y_groundTruth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function - gameAttriGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param dfFile: pandas.DataFrame ('nba_preprocessed.csv')\n",
    "# @param dateStart, dateEnd: str in the format of 'YYYY-MM-DD'\n",
    "# @param period: int\n",
    "# @param Team_A, Team_B: str (If both are None, predict all games within the date range)\n",
    "# @param featureSel: int\n",
    "# @return X, Y: pandas.DataFrame\n",
    "# gameAttriGen() outputs X_attri, Y_truth for game prediction.\n",
    "def gameAttriGen(dfFile, dateStart, dateEnd, period=5, Team_A=None, Team_B=None, featureSel=None):\n",
    "    df = pd.read_csv(dfFile)\n",
    "    \n",
    "    # Date selections\n",
    "    df_sel = df.loc[(df.Date_A >= dateStart) & (df.Date_A <= dateEnd), :].reset_index(drop=True)\n",
    "    \n",
    "    # Generate df_sel which includes [date, Team_A, Team_B] columns\n",
    "    if Team_A and Team_B:\n",
    "        df_sel = df_sel.loc[(df_sel.Team_A == Team_A) & (df_sel.Opponent_A == Team_B), :].reset_index(drop=True)[['Date_A', 'Team_A', 'Opponent_A']]\n",
    "    elif Team_A and not Team_B:\n",
    "        df_sel = df_sel.loc[df_sel.Team_A == Team_A, :].reset_index(drop=True)[['Date_A', 'Team_A', 'Opponent_A']]\n",
    "    elif not Team_A and Team_B:\n",
    "        df_sel = df_sel.loc[df_sel.Opponent_A == Team_B, :].reset_index(drop=True)[['Date_A', 'Team_A', 'Opponent_A']]\n",
    "    elif not Team_A and not Team_B:\n",
    "        df_sel = df_sel[['Date_A', 'Team_A', 'Opponent_A']]\n",
    "        # Delete duplicates: (Team_A vs Team_B) is the same as (Team_B vs Team_A). Remove one to avoid double count.\n",
    "        df_new = pd.DataFrame(columns=['Date_A', 'Team_A', 'Opponent_A'])\n",
    "        LUT = {}\n",
    "        for date, x, y in zip(df_sel['Date_A'], df_sel['Team_A'], df_sel['Opponent_A']):\n",
    "            if (date + x + y) in LUT:\n",
    "                df_new = pd.concat([df_new, pd.DataFrame(columns=['Date_A', 'Team_A', 'Opponent_A'], data=[[date, x, y]])], ignore_index=True)\n",
    "            else:\n",
    "                LUT[date + x + y] = 1\n",
    "                LUT[date + y + x] = 1\n",
    "        df_sel = df_new\n",
    "    \n",
    "    # W/L prediction\n",
    "    X_attri = Y_truth = None\n",
    "    for date, Team_A, Team_B in zip(df_sel['Date_A'], df_sel['Team_A'], df_sel['Opponent_A']):\n",
    "        X_toBePredicted = attriGen(df, date, period, Team_A, Team_B, None, featureSel)\n",
    "        X_groundTruth, Y_groundTruth = groundTruthGen(df, date, Team_A, Team_B, featureSel)\n",
    "        if X_attri is None and Y_truth is None:\n",
    "            X_attri = X_toBePredicted\n",
    "            Y_truth = Y_groundTruth\n",
    "        else:\n",
    "            X_attri = pd.concat([X_attri, X_toBePredicted], ignore_index=True)\n",
    "            Y_truth = pd.concat([Y_truth, Y_groundTruth], ignore_index=True)\n",
    "        \n",
    "    return X_attri, Y_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function - gamePrediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param dfFile: pandas.DataFrame ('nba_preprocessed.csv')\n",
    "# @param modelsLUT: dict in the format of {'modelName': model}\n",
    "# @param dateStart, dateEnd: str in the format of 'YYYY-MM-DD'\n",
    "# @param period: int (Number of previous games to be considered)\n",
    "# @param Team_A, Team_B: str (If both are None, predict all games within the date range)\n",
    "# @param featureSel: int\n",
    "# @return None\n",
    "# gamePrediction() prints the predicted game W/L results.\n",
    "def gamePrediction(dfFile, modelsLUT, dateStart, dateEnd, period=5, Team_A=None, Team_B=None, featureSel=None):\n",
    "    X_attri, Y_truth = gameAttriGen(dfFile, dateStart, dateEnd, period, Team_A, Team_B, featureSel)\n",
    "    \n",
    "    resultLUT, accuLUT = {}, {}\n",
    "    for model in modelsLUT:\n",
    "        resultLUT[model] = modelsLUT[model].predict(X_attri)\n",
    "        accuLUT[model] = accuracy_score(Y_truth, modelsLUT[model].predict(X_attri))\n",
    "    \n",
    "    print('---------- Prediction Accuracy ----------')\n",
    "    print('featureSel =', featureSel)\n",
    "    for x in accuLUT:\n",
    "        print(x, '=', accuLUT[x]*100, '%')\n",
    "    print('------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction results of 2018 playoff games\n",
    "- AdaBoost w/ cross validation and grid search has the highest accuracy.\n",
    "- Random Forest and AdaBoost are improved significantly by grid search.\n",
    "- Logistic Regression and XGBoost are not improved by grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Prediction Accuracy ----------\n",
      "featureSel = 3\n",
      "logiRegr = 71.95121951219512 %\n",
      "logiRegrCVGS = 71.95121951219512 %\n",
      "xgbc = 73.17073170731707 %\n",
      "xgbcCVGS = 73.17073170731707 %\n",
      "randomForest = 60.97560975609756 %\n",
      "randomForestCVGS = 71.95121951219512 %\n",
      "adaBoost = 69.51219512195121 %\n",
      "adaBoostCVGS = 76.82926829268293 %\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfFile = 'nba_preprocessed.csv'\n",
    "dateStart = '2018-04-14'\n",
    "dateEnd = '2018-06-08'\n",
    "period = 5\n",
    "Team_A = None\n",
    "Team_B = None\n",
    "featureSel = 3\n",
    "\n",
    "# W/L prediction\n",
    "gamePrediction(dfFile, modelsLUT, dateStart, dateEnd, period, Team_A, Team_B, featureSel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
